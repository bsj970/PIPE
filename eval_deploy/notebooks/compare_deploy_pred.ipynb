{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark different map predictions with simple robot observation in-the-loop\n",
    "* can be given a trajectory, or (later on) with exploration using predicted map in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Third party imports\n",
    "import torch\n",
    "import os \n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.patches as patches\n",
    "from torchmetrics.classification import JaccardIndex\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage.morphology import distance_transform_cdt\n",
    "\n",
    "# Custom imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "# from gen_building_utils import * \n",
    "from options.deploy_options import *\n",
    "from models.predictors import get_predictor_from_options\n",
    "from eval_deploy import deploy_utils as dutils\n",
    "from eval_deploy import viz_utils as vutils\n",
    "from eval_deploy import glocal_utils as glocal\n",
    "from data_factory import gen_building_utils \n",
    "from data_factory import simple_mask_utils as smu\n",
    "\n",
    "# refresh jupyter modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem Inputs \n",
    "ensemble_folder_name = 'sc_map_pred_ensemble1' # Path to ensemble folder, in weights folder\n",
    "map_configs = {\n",
    "    'min_start_end_dist': 50,\n",
    "    'collect_interval_m': 5,\n",
    "    'laser_range': 50,\n",
    "    'num_laser': 500,\n",
    "    'num_rand_traj_per_map':1,\n",
    "    'percent_test': 0.2,\n",
    "    \"local_map_size\": 30, # TODO: add multiplier \n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialize deploy variables given main variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: loading checkpoint /home/cherie/research/hmap/map_prediction_toolbox/weights/sc_map_pred_ensemble1/sc_map_pred_v1_0/checkpoints/2023_08_01-09_13_05.pt\n",
      "Model 1: loading checkpoint /home/cherie/research/hmap/map_prediction_toolbox/weights/sc_map_pred_ensemble1/sc_map_pred_v1_1/checkpoints/2023_08_01-09_37_10.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize options\n",
    "cmd_line_args_dict = ['--name', 'deploy']\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.environ['L2M_root_path'] = '/home/cherie/research/hmap/map_prediction_toolbox/' # change for different computer\n",
    "options = DeployOptions().parse_args(cmd_line_args_dict)\n",
    "\n",
    "# Initialize model ensembles # TODO: make into function\n",
    "ensemble_dir = os.path.join(options.root_path, 'weights', ensemble_folder_name)\n",
    "assert os.path.exists(ensemble_dir), \"Ensemble dir does not exist\"\n",
    "ensemble_exp = os.listdir(ensemble_dir)\n",
    "ensemble_exp.sort()\n",
    "models_dict = {}\n",
    "ensemble_size = len(ensemble_exp)\n",
    "for n in range(ensemble_size):\n",
    "    models_dict[n] = {'predictor_model': get_predictor_from_options(options)}\n",
    "    models_dict[n] = {k:v.to(device) for k,v in models_dict[n].items()}\n",
    "    models_dict[n]['predictor_model'] = torch.nn.DataParallel(models_dict[n]['predictor_model'])\n",
    "    checkpoint_dir = ensemble_dir + \"/\" + ensemble_exp[n]\n",
    "    latest_checkpoint = dutils.get_latest_model(save_dir=checkpoint_dir)\n",
    "    models_dict[n] = dutils.load_model(models=models_dict[n], checkpoint_file=latest_checkpoint)\n",
    "    models_dict[n][\"predictor_model\"].eval()\n",
    "    print(\"Model {}: loading checkpoint {}\".format(n, latest_checkpoint))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make random map and trajectory, then get local observations\n",
    "* should be similar to gen_building_mask\n",
    "* Observation is local map mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "start: (21, 6), end: (91, 18)\n",
      "Map shape:  (600, 300)\n",
      "Mask list shape:  (600, 300)\n"
     ]
    }
   ],
   "source": [
    "# Generate a global ground-truth occupancy grid \n",
    "building_occ_map = gen_building_utils.make_building_occ_map()\n",
    "building_occ_map = smu.convert_012_labels_to_maskutils_labels(building_occ_map)\n",
    "\n",
    "# Randomize if transpose \n",
    "\n",
    "if np.random.rand() > 0.5:\n",
    "    building_occ_map = building_occ_map.T\n",
    "# \n",
    "\n",
    "plt.imshow(building_occ_map)\n",
    "plt.title(\"Global map\")\n",
    "plt.show()\n",
    "\n",
    "# Get list of local masks given a random trajectory\n",
    "# TODO: set it to take in a trajectory instead \n",
    "map, mask_list, local_mask_list, local_gt_list, pose_list = smu.make_masklist_with_rand_traj_in_map(building_occ_map, map_configs, show_viz=False)\n",
    "\n",
    "# Make everything 5 times bigge\n",
    "multiplier = 5\n",
    "map = dutils.make_map_larger(map, multiplier)\n",
    "mask_list = [dutils.make_map_larger(map, multiplier) for map in mask_list]\n",
    "local_mask_list = [dutils.make_map_larger(map, multiplier) for map in local_mask_list]\n",
    "local_gt_list = [dutils.make_map_larger(map, multiplier) for map in local_gt_list]\n",
    "pose_list = pose_list * multiplier\n",
    "\n",
    "\n",
    "print(\"Map shape: \", map.shape)\n",
    "print(\"Mask list shape: \", mask_list[0].shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark different prediction strategy with robot in loop \n",
    "* Given global ground truth map and trajectory above, we measure map error for different map prediction strategy\n",
    "\n",
    "Strategies:\n",
    "* No Map Prediction\n",
    "* Local Prediction\n",
    "* GLocal (Naive): Don't propagate map\n",
    "* GLocal (Propagation)\n",
    "\n",
    "Psuedocode:\n",
    "```\n",
    "* For each point in trajectory, we want to mock the prediction process\n",
    "    * get current observed map\n",
    "    * get predicted map (depends on strategy)\n",
    "    * if needed, get indices of local predicted map in global map\n",
    "    * update global map with local map\n",
    "    * visualize global predicted map \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherie/mambaforge/envs/map_pred/lib/python3.6/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SSIM` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:01<00:34,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:03<00:33,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:36,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:09<00:36,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:11<00:35,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:14<00:34,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:17<00:32,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:19<00:30,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:22<00:28,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:25<00:26,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:27<00:23,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:30<00:21,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:33<00:19,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:36<00:16,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:38<00:13,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:41<00:10,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:44<00:08,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:47<00:05,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:49<00:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pred_onehot_tensor_list.shape: torch.Size([2, 3, 600, 300])\n",
      "global_pred_propagate_onehot_tensor_rollouts.shape:  torch.Size([2, 3, 600, 300])\n",
      "i:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:52<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Intialize transform \n",
    "local_transform = Compose([\n",
    "            Resize((256, 256), interpolation= PIL.Image.NEAREST),\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "global_transform = Compose([\n",
    "            ToTensor(),\n",
    "        ]) # do not do any resizing\n",
    "\n",
    "# Initialize metric function \n",
    "iou_metric = JaccardIndex(task=\"multiclass\", num_classes=3, reduction=\"none\")\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0, reduction=\"none\")\n",
    "\n",
    "\n",
    "# Initialize metric lists for visualization \n",
    "iou_metric_obs_list = []\n",
    "iou_metric_pred_list = []\n",
    "iou_metric_pred_multi_list = []\n",
    "iou_metric_pred_propagated_list = [] \n",
    "ssim_metric_obs_list = [] \n",
    "ssim_metric_pred_list = []\n",
    "ssim_metric_pred_multi_list = []\n",
    "ssim_metric_pred_propagated_list = []\n",
    "\n",
    "\n",
    "# Initialize global maps for accumulation\n",
    "init_value = 2 # init as free space\n",
    "\n",
    "## Global map observed\n",
    "global_map_obs = np.ones_like(map) * init_value \n",
    "global_obs_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_obs, global_transform)\n",
    "\n",
    "## Global map predicted\n",
    "global_map_pred = np.ones_like(map) * init_value \n",
    "global_pred_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_pred, global_transform)\n",
    "\n",
    "## Global map predicted multi-patches \n",
    "global_map_pred_multi = np.ones_like(map) * init_value\n",
    "global_pred_multi_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_pred_multi, global_transform)\n",
    "\n",
    "## Global map predicted propagated\n",
    "global_map_pred_propagated = np.ones_like(map) * init_value\n",
    "global_pred_propagated_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_pred_propagated, global_transform)\n",
    "\n",
    "\n",
    "\n",
    "## Collect metrics over trajectory\n",
    "for i in tqdm(range(len(mask_list))):\n",
    "    # Get local observed map\n",
    "    local_observed_map = 1-local_mask_list[i]\n",
    "    global_observed_map = 1-mask_list[i]\n",
    "\n",
    "    # Get local predicted map    \n",
    "    local_input_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(local_observed_map, local_transform)\n",
    "    local_pred_mean_onehot, local_pred_ensemble_onehot = dutils.run_map_predictor(local_input_onehot_tensor, device, models_dict)\n",
    "\n",
    "\n",
    "    # Get local GT map (for visualization)\n",
    "    local_gt_map = 1-local_gt_list[i]\n",
    "    local_gt_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(local_gt_map, local_transform)\n",
    "\n",
    "    # Get global GT map (for visualization)\n",
    "    global_map_gt = map \n",
    "    global_gt_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_gt, global_transform)\n",
    "\n",
    "    # Accumulate global observed map\n",
    "    local_map_center_in_global = pose_list[i]\n",
    "    \n",
    "    # # Update global observed map with newest global observed map \n",
    "    global_obs_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_observed_map, global_transform)\n",
    "    # For metrics, get observed map where unobserved is free space \n",
    "    global_obs_freespace_tensor = dutils.change_onehot_unobserved_to_free(global_obs_onehot_tensor)\n",
    "    # print(\"global_obs_onehot_tensor.shape: \", global_obs_onehot_tensor.shape)\n",
    "    # print(\"global_observed_map.shape: \", global_observed_map.shape)\n",
    "    # plt.imshow(global_observed_map)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    # # Update global predicted map with local predicted map\n",
    "    global_pred_onehot_tensor = dutils.update_global_map_with_local(global_pred_onehot_tensor, local_pred_mean_onehot, \n",
    "                                 robot_pose=local_map_center_in_global, local_map_size=map_configs['local_map_size']*multiplier)\n",
    "\n",
    "    # # Update global predicted multi map with multi-patch inference\n",
    "    stride_m = 10 # TODO: move up to config, should have seperate prediction config \n",
    "    global_pred_multi_onehot_tensor = glocal.calculate_global_pred_with_glocal_inference(global_obs_onehot_tensor,\n",
    "                                                    global_pred_multi_onehot_tensor, \n",
    "                                                    map_configs, multiplier, \n",
    "                                                    stride_m, models_dict, \n",
    "                                                    device, show_viz=False)\n",
    "    \n",
    "    # # Get patch distance transform \n",
    "    known_threshold = 0.3 # TODO: move up to config, should have seperate prediction config \n",
    "    global_pred_propagate_onehot_tensor_rollouts = glocal.calculate_rollouts_global_map_prediction(models_dict, device, global_obs_onehot_tensor, map_configs, multiplier, stride_m, known_threshold, show_viz=False)\n",
    "    print(\"global_pred_propagate_onehot_tensor_rollouts.shape: \", global_pred_propagate_onehot_tensor_rollouts.shape)\n",
    "    global_pred_propagate_onehot_tensor_mean = torch.mean(global_pred_propagate_onehot_tensor_rollouts, dim=0).unsqueeze(0)\n",
    "\n",
    "    # Get the variance \n",
    "    var_class = 1\n",
    "    variance_global_pred_propagate_onehot_tensor = torch.var(global_pred_propagate_onehot_tensor_rollouts[:,var_class,:,:], dim=0)\n",
    "\n",
    "    \n",
    "    # # Calculate metrics\n",
    "    ssim_metric_obs = dutils.get_ssim(ssim_metric, global_obs_freespace_tensor, global_gt_onehot_tensor)\n",
    "    ssim_metric_obs_list.append(ssim_metric_obs)\n",
    "\n",
    "    global_pred_freespace_tensor = dutils.change_onehot_unobserved_to_free(global_pred_onehot_tensor)\n",
    "    ssim_metric_pred = dutils.get_ssim(ssim_metric, global_pred_freespace_tensor, global_gt_onehot_tensor)\n",
    "    ssim_metric_pred_list.append(ssim_metric_pred)\n",
    "\n",
    "    global_pred_multi_freespace_tensor = dutils.change_onehot_unobserved_to_free(global_pred_multi_onehot_tensor)\n",
    "    ssim_metric_pred_multi = dutils.get_ssim(ssim_metric, global_pred_multi_freespace_tensor, global_gt_onehot_tensor)\n",
    "    ssim_metric_pred_multi_list.append(ssim_metric_pred_multi)\n",
    "\n",
    "    global_pred_propagated_freespace_tensor = dutils.change_onehot_unobserved_to_free(global_pred_propagate_onehot_tensor_mean)\n",
    "    ssim_metric_pred_propagated = dutils.get_ssim(ssim_metric, global_pred_propagated_freespace_tensor, global_gt_onehot_tensor)\n",
    "    ssim_metric_pred_propagated_list.append(ssim_metric_pred_propagated)\n",
    "\n",
    "\n",
    "    iou_metric_obs = dutils.get_freq_iou(iou_metric, global_obs_freespace_tensor, global_gt_onehot_tensor)\n",
    "    iou_metric_obs_list.append(iou_metric_obs)\n",
    "\n",
    "    iou_metric_pred = dutils.get_freq_iou(iou_metric, global_pred_freespace_tensor, global_gt_onehot_tensor)\n",
    "    # print(\"iou_metric_pred: \", iou_metric_pred)\n",
    "    iou_metric_pred_list.append(iou_metric_pred)\n",
    "\n",
    "    iou_metric_pred_multi = dutils.get_freq_iou(iou_metric, global_pred_multi_freespace_tensor, global_gt_onehot_tensor)\n",
    "    # print(\"iou_metric_pred_multi: \", iou_metric_pred_multi)\n",
    "    iou_metric_pred_multi_list.append(iou_metric_pred_multi)\n",
    "\n",
    "    iou_metric_pred_propagated = dutils.get_freq_iou(iou_metric, global_pred_propagated_freespace_tensor, global_gt_onehot_tensor)\n",
    "    # print(\"iou_metric_pred_propagated: \", iou_metric_pred_propagated)\n",
    "    iou_metric_pred_propagated_list.append(iou_metric_pred_propagated)\n",
    "\n",
    "    # Converting one hot tensors to colorized and then visualize \n",
    "    plt_row = 3\n",
    "    plt_col = 4\n",
    "\n",
    "    plot_num_global_gt = 1\n",
    "    plot_num_local_input = 2\n",
    "    plot_num_local_pred = 3\n",
    "    plot_num_metrics = 4\n",
    "    plot_num_global_obs = 5\n",
    "    plot_num_global_pred = 6\n",
    "    plot_num_global_pred_multi = 7\n",
    "    plot_num_global_pred_propagated = 8\n",
    "    plot_num_prop_pred_1 = 9 \n",
    "    plot_num_prop_pred_2 = 10\n",
    "    plot_num_prop_var = 11\n",
    "    plot_num_prop_var_subsampled = 12\n",
    "\n",
    "    plt.figure(figsize=(20,12), facecolor=(1,1,1))\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_global_gt)\n",
    "    colorized_gt_global = vutils.get_colorized_map(global_gt_onehot_tensor)\n",
    "    plt.imshow(colorized_gt_global.permute(1,2,0).squeeze().detach().cpu().numpy()) \n",
    "    x_pose = pose_list[i,0]\n",
    "    y_pose = pose_list[i,1]\n",
    "    \n",
    "    plt.scatter(y_pose, x_pose,c='r',marker='x', s=100) # robot pose \n",
    "    plt.plot(pose_list[:i+1,1], pose_list[:i+1,0],'r.') # robot past traj \n",
    "    local_map_size_multiplied = map_configs['local_map_size'] * multiplier\n",
    "    rect = patches.Rectangle((y_pose - (local_map_size_multiplied/2), x_pose - (local_map_size_multiplied/2)), local_map_size_multiplied, local_map_size_multiplied, \n",
    "                             linewidth=2, edgecolor='r', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "    # make a rectangle\n",
    "    plt.title(\"Global map gt\")\n",
    "\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_local_input)\n",
    "    # plt.imshow(local_observed_map)\n",
    "    colorized_input = vutils.get_colorized_map(local_input_onehot_tensor)\n",
    "    colorized_input_permuted = colorized_input.permute(1,2,0).squeeze().detach().cpu().numpy()\n",
    "    plt.imshow(colorized_input_permuted)\n",
    "    plt.scatter(colorized_input_permuted.shape[1]//2, colorized_input_permuted.shape[0]//2,c='r', s=10) # robot pose\n",
    "    plt.title(\"Local map input\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_local_pred)\n",
    "    colorized_mean = vutils.get_colorized_map(local_pred_mean_onehot)\n",
    "    plt.imshow(colorized_mean.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.scatter(colorized_input_permuted.shape[1]//2, colorized_input_permuted.shape[0]//2,c='r', s=10) # robot pose\n",
    "    plt.title(\"Local map predicted\")\n",
    "\n",
    "    # plt.subplot(plt_row,plt_col,3)\n",
    "    # colorized_gt = vutils.get_colorized_map(local_gt_onehot_tensor)\n",
    "    # plt.imshow(colorized_gt.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    # plt.scatter(colorized_input_permuted.shape[1]//2, colorized_input_permuted.shape[0]//2,c='r', s=10) # robot pose\n",
    "    # plt.title(\"Local map GT\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_global_obs)\n",
    "    colorized_obs_global = vutils.get_colorized_map(global_obs_freespace_tensor)\n",
    "    plt.imshow(colorized_obs_global.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"No Map Prediction\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_global_pred)\n",
    "    colorized_pred_global = vutils.get_colorized_map(global_pred_freespace_tensor)\n",
    "    plt.imshow(colorized_pred_global.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"Only Local Prediction\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_global_pred_multi)\n",
    "    colorized_pred_global_mult = vutils.get_colorized_map(global_pred_multi_freespace_tensor)\n",
    "    plt.imshow(colorized_pred_global_mult.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"GLocal: No Propagation\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_global_pred_propagated)\n",
    "    colorized_pred_global_propagated = vutils.get_colorized_map(global_pred_propagated_freespace_tensor)\n",
    "    plt.imshow(colorized_pred_global_propagated.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"GLocal: With Propagation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## Metrics \n",
    "    plt.subplot(plt_row,plt_col,plot_num_metrics)\n",
    "    # plt.plot(iou_metric_obs_list, label=\"No Pred.\")\n",
    "    # plt.plot(iou_metric_pred_list, label=\"Local Pred.\")\n",
    "    # plt.plot(iou_metric_pred_multi_list, label=\"GLocal: No Prop.\")\n",
    "    # plt.plot(iou_metric_pred_propagated_list, label=\"GLocal: With Prop.\")\n",
    "    # plt.title(\"Freq-weighted IOU metric\")\n",
    "\n",
    "    plt.plot(ssim_metric_obs_list, label=\"No Pred. (SSIM)\")\n",
    "    plt.plot(ssim_metric_pred_list, label=\"Local Pred. (SSIM)\")\n",
    "    plt.plot(ssim_metric_pred_multi_list, label=\"GLocal: No Prop. (SSIM)\")\n",
    "    plt.plot(ssim_metric_pred_propagated_list, label=\"GLocal: With Prop. (SSIM)\") \n",
    "    plt.title(\"SSIM metric\")\n",
    "    plt.xlim(0, len(mask_list))\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    \n",
    "    # # Plot variance of multiple propagataion \n",
    "    plt.subplot(plt_row,plt_col,plot_num_prop_pred_1)\n",
    "    colorized_pred_global_propagated = vutils.get_colorized_map(global_pred_propagate_onehot_tensor_rollouts[0].unsqueeze(0))\n",
    "    plt.imshow(colorized_pred_global_propagated.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"GLocal: Prop. 1\")\n",
    "\n",
    "    plt.subplot(plt_row,plt_col,plot_num_prop_pred_2)\n",
    "    colorized_pred_global_propagated = vutils.get_colorized_map(global_pred_propagate_onehot_tensor_rollouts[1].unsqueeze(0))\n",
    "    plt.imshow(colorized_pred_global_propagated.permute(1,2,0).squeeze().detach().cpu().numpy())\n",
    "    plt.title(\"GLocal: Prop. 2\")\n",
    "    \n",
    "\n",
    "    plt.subplot(plt_row, plt_col, plot_num_prop_var)\n",
    "    plt.imshow(variance_global_pred_propagate_onehot_tensor,vmin=0, vmax=1)\n",
    "    plt.title(\"variance of class {}\".format(var_class))\n",
    "    plt.colorbar()\n",
    "\n",
    "    subsampling_freq = 50\n",
    "\n",
    "    subsampled = np.zeros((int(variance_global_pred_propagate_onehot_tensor.shape[0]/subsampling_freq), int(variance_global_pred_propagate_onehot_tensor.shape[1]/subsampling_freq)))\n",
    "    for sub_i in range(int(variance_global_pred_propagate_onehot_tensor.shape[0]/subsampling_freq)):\n",
    "        for sub_j in range(int(variance_global_pred_propagate_onehot_tensor.shape[1]/subsampling_freq)):\n",
    "            query_patch = variance_global_pred_propagate_onehot_tensor[sub_i*subsampling_freq:(sub_i+1)*subsampling_freq,sub_j*subsampling_freq:(sub_j+1)*subsampling_freq]\n",
    "            subsampled[sub_i,sub_j] = torch.sum(query_patch)\n",
    "    plt.subplot(plt_row, plt_col, plot_num_prop_var_subsampled)\n",
    "    plt.imshow(subsampled, vmin=0, vmax = 500)\n",
    "    plt.title(\"subsampled\")\n",
    "    plt.colorbar()\n",
    "    print(\"i: \", i)\n",
    "    plt.savefig(\"outputs/plot_{:04d}.png\".format(i))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0139)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_metric_obs = ssim_metric(torch.argmax(global_obs_onehot_tensor, dim=1).float().unsqueeze(1), target_tensor_argmax.float().unsqueeze(1))\n",
    "# torch.argmax(global_gt_onehot_tensor, dim=1).shape\n",
    "# target_tensor_argmax.shape\n",
    "ssim_metric_obs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get and visualize local patches\n",
    "We want a figure where \n",
    "* on the left, we show global map with rectangles around the frames\n",
    "* on the right, we show the patches and then maybe underneath the associated predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get global GT map (for visualization)\n",
    "# i = 0\n",
    "# global_map_gt = map \n",
    "# global_gt_onehot_tensor = dutils.convert_maputils_labelmaps_to_model_input_format(global_map_gt, global_transform)\n",
    "\n",
    "# x_pose = pose_list[i,0]\n",
    "# y_pose = pose_list[i,1]\n",
    "\n",
    "# plt.scatter(y_pose, x_pose,c='r',marker='x', s=100) # robot pose \n",
    "# plt.plot(pose_list[:i+1,1], pose_list[:i+1,0],'r.') # robot past traj \n",
    "# local_map_size_multiplied = map_configs['local_map_size'] * multiplier\n",
    "# # rect = patches.Rectangle((y_pose - (local_map_size_multiplied/2), x_pose - (local_map_size_multiplied/2)), local_map_size_multiplied, local_map_size_multiplied, \n",
    "# #                             linewidth=3, edgecolor='r', facecolor='none')\n",
    "# # plt.gca().add_patch(rect)\n",
    "\n",
    "# colorized_obs_global = vutils.get_colorized_map(global_obs_onehot_tensor)\n",
    "# plt.imshow(colorized_obs_global.permute(1,2,0).squeeze().detach().cpu().numpy()) \n",
    "# plt.title(\"Global Obs map\")\n",
    "\n",
    "\n",
    "# # Given the global map shape and stride, get list of patch centers\n",
    "# stride = [10 * multiplier, 10* multiplier] \n",
    "# patch_shape = [map_configs['local_map_size'] * multiplier, map_configs['local_map_size'] * multiplier]\n",
    "# patch_centers = dutils.get_patch_centers(global_map_gt.shape, patch_shape, stride)\n",
    "# print(\"Number of patches: \", len(patch_centers))\n",
    "# # print(\"Patch centers: \", patch_centers)\n",
    "\n",
    "# # Visualize the patch centers\n",
    "# plt.scatter(patch_centers[:,1], patch_centers[:,0], c='b', marker='x', s=100) # patch centers\n",
    "# for patch_center in patch_centers:\n",
    "#     rect = patches.Rectangle((patch_center[1] - (local_map_size_multiplied/2), patch_center[0] - (local_map_size_multiplied/2)), local_map_size_multiplied, local_map_size_multiplied, \n",
    "#                             linewidth=3, edgecolor=vutils.generate_random_color(), facecolor='none')\n",
    "#     plt.gca().add_patch(rect)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get patches from global map given the patch centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stride_m = 10 # meters\n",
    "# global_pred_onehot_tensor = glocal.calculate_global_pred_with_glocal_inference(global_obs_onehot_tensor,\n",
    "#                                                    global_pred_onehot_tensor, \n",
    "#                                                    map_configs, multiplier, \n",
    "#                                                    stride_m, models_dict, \n",
    "#                                                    device, show_viz=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype Iterative Map Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutils.change_onehot_unobserved_to_free(global_obs_onehot_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_global_pred_propagate_onehot_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_obs_onehot_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85f389138e2ef9a10ae90a13a7022fc709fb836248c0afbb2cd1456d820047f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
